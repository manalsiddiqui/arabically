import { NextApiRequest, NextApiResponse } from 'next'
import formidable, { IncomingForm } from 'formidable'
import { v4 as uuidv4 } from 'uuid'
import { storeEmbeddings } from '@/lib/ai/rag'
import { createClient } from '@supabase/supabase-js'
import fs from 'fs'
import mammoth from 'mammoth'
import pdfParse from 'pdf-parse'

export const config = {
  api: {
    bodyParser: false,
    responseLimit: false, // Disable response limit for large files
  },
}

async function handler(req: NextApiRequest, res: NextApiResponse) {
  if (req.method !== 'POST') {
    return res.status(405).json({ error: 'Method not allowed' })
  }

  console.log('üöÄ Starting file upload process...')

  try {
    // Parse the multipart form data with larger size limits
    const form = new IncomingForm({
      maxFileSize: 50 * 1024 * 1024, // 50MB
      maxTotalFileSize: 50 * 1024 * 1024, // 50MB total
      maxFields: 20, // Allow more form fields
      maxFieldsSize: 2 * 1024 * 1024, // 2MB for form fields
    })
    
    console.log('üìù Parsing form data...')
    const [fields, files] = await form.parse(req)

    const file = Array.isArray(files.file) ? files.file[0] : files.file
    if (!file) {
      console.error('‚ùå No file uploaded')
      return res.status(400).json({ error: 'No file uploaded' })
    }

    console.log(`üìÑ File received: ${file.originalFilename} (${(file.size / 1024 / 1024).toFixed(2)}MB)`)

    // Get form data
    const title = Array.isArray(fields.title) ? fields.title[0] : fields.title
    const ageGroup = Array.isArray(fields.ageGroup) ? fields.ageGroup[0] : fields.ageGroup
    const subject = Array.isArray(fields.subject) ? fields.subject[0] : fields.subject
    const tags = Array.isArray(fields.tags) ? fields.tags[0] : fields.tags
    const language = Array.isArray(fields.language) ? fields.language[0] : fields.language
    const extractedText = Array.isArray(fields.extractedText) ? fields.extractedText[0] : fields.extractedText

    if (!title || !extractedText) {
      console.error('‚ùå Missing required fields:', { title: !!title, extractedText: !!extractedText })
      return res.status(400).json({ error: 'Title and extracted text are required' })
    }

    console.log('‚úÖ Form data validated')

    // Create Supabase client with service role key for file uploads
    const supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL!,
      process.env.SUPABASE_SERVICE_ROLE_KEY!,
      {
        auth: {
          autoRefreshToken: false,
          persistSession: false
        }
      }
    )

    // Generate unique filename
    const fileExtension = file.originalFilename?.split('.').pop() || 'unknown'
    const uniqueFilename = `${uuidv4()}.${fileExtension}`
    const filePath = `lesson-plans/${uniqueFilename}`

    // Process tags
    const tagsArray = tags ? tags.split(',').map((tag: string) => tag.trim()).filter(Boolean) : []

    // Extract text from file on server-side if needed
    let finalExtractedText = extractedText
    let processingError = null

    if (extractedText.includes('[File:') && extractedText.includes('Text will be extracted on server')) {
      console.log('üîÑ Extracting text on server...')
      try {
        const fileExtension = file.originalFilename?.split('.').pop()?.toLowerCase()
        const fileBuffer = fs.readFileSync(file.filepath)

        console.log(`üìÑ Processing ${fileExtension} file: ${(fileBuffer.length / 1024 / 1024).toFixed(2)}MB`)

        if (fileExtension === 'pdf') {
          const pdfData = await pdfParse(fileBuffer, {
            max: 10000, // Limit to 10,000 characters to prevent memory issues
          })
          
          if (!pdfData.text || pdfData.text.trim().length < 10) {
            // For image-based PDFs, create a more descriptive fallback
            const fileName = file.originalFilename || 'unknown'
            const pages = pdfData.numpages || 'unknown'
            finalExtractedText = `Lesson Plan: ${fileName} (${pages} pages). This appears to be an image-based PDF. The content includes educational material that can be used for teaching. File contains visual elements that require manual review for detailed content extraction.`
            console.log(`‚ö†Ô∏è Image-based PDF detected, using descriptive fallback: ${finalExtractedText.length} characters`)
          } else {
            finalExtractedText = pdfData.text.substring(0, 10000) // Reduced limit
            console.log(`‚úÖ PDF text extracted: ${finalExtractedText.length} characters`)
          }

        } else if (fileExtension === 'docx') {
          const result = await mammoth.extractRawText({ buffer: fileBuffer })
          
          if (!result.value || result.value.trim().length < 10) {
            const fileName = file.originalFilename || 'unknown'
            finalExtractedText = `Lesson Plan: ${fileName}. This appears to be a DOCX file with limited readable text. The content includes educational material that can be used for teaching.`
            console.log(`‚ö†Ô∏è DOCX with minimal text detected, using descriptive fallback: ${finalExtractedText.length} characters`)
          } else {
            finalExtractedText = result.value.substring(0, 10000) // Reduced limit
            console.log(`‚úÖ DOCX text extracted: ${finalExtractedText.length} characters`)
          }

        } else {
          finalExtractedText = extractedText
        }

        // Clean up temporary file immediately after processing
        try {
          fs.unlinkSync(file.filepath)
          console.log('üóëÔ∏è Temporary file cleaned up')
        } catch (cleanupError) {
          console.warn('‚ö†Ô∏è Could not clean up temporary file:', cleanupError)
        }

      } catch (extractionError: any) {
        console.error('‚ùå Server-side text extraction error:', extractionError.message)
        processingError = `Text extraction failed: ${extractionError.message}`
        
        // Create a meaningful fallback text instead of just error message
        const fileName = file.originalFilename || 'unknown'
        const fileSize = `${(file.size / 1024).toFixed(1)}KB`
        finalExtractedText = `Lesson Plan: ${fileName} (${fileSize}). This educational document contains teaching material and resources. Content extraction was limited, but the file can still be used as a reference for lesson planning and educational activities.`
        
        console.log(`‚ö†Ô∏è Using fallback text: ${finalExtractedText.length} characters`)
      }
    }

    // Validate extracted text length
    const isServerProcessedFile = extractedText.includes('Text will be extracted on server')
    const minLength = isServerProcessedFile ? 5 : 10 // More lenient for server-processed files
    
    if (finalExtractedText.length < minLength) {
      console.error('‚ùå Extracted text too short:', finalExtractedText.length)
      
      // If it's a server-processed file that failed, provide more specific error
      if (isServerProcessedFile && processingError) {
        return res.status(400).json({ 
          error: `Unable to extract text from ${file.originalFilename}. ${processingError}. Please try a different file or format.`
        })
      }
      
      return res.status(400).json({ 
        error: 'File content appears to be empty or unreadable. Please try a different file format.' 
      })
    }

    console.log('üíæ Saving lesson plan to database...')

    // Save lesson plan to database
    const { data: lessonPlan, error: dbError } = await supabase
      .from('lesson_plans')
      .insert({
        user_id: null, // Set to null since we made it nullable for testing
        title,
        original_filename: file.originalFilename || 'unknown',
        file_path: filePath,
        file_type: file.mimetype || 'application/octet-stream',
        file_size: file.size,
        extracted_text: finalExtractedText,
        tags: tagsArray,
        age_group: ageGroup || null,
        subject: subject || null,
        language: language || 'ar',
      })
      .select()
      .single()

    if (dbError) {
      console.error('‚ùå Database error:', dbError)
      return res.status(500).json({ error: 'Failed to save lesson plan to database' })
    }

    console.log(`‚úÖ Lesson plan saved with ID: ${lessonPlan.id}`)

    // Store embeddings for RAG (async, don't wait for completion)
    // Only generate embeddings if we have substantial content
    if (finalExtractedText.length > 200 && !finalExtractedText.includes('Content extraction was limited')) {
      console.log('üß† Starting embedding generation...')
      storeEmbeddings(lessonPlan.id, finalExtractedText)
        .then(() => {
          console.log(`‚úÖ Embeddings stored successfully for lesson: ${lessonPlan.id}`)
        })
        .catch((embeddingError) => {
          console.error('‚ùå Embedding error (non-blocking):', embeddingError)
        })
    } else {
      console.log('‚ö†Ô∏è Skipping embedding generation for limited content to prevent memory issues')
    }

    // Return success immediately (don't wait for embeddings)
    const response = {
      success: true,
      lessonPlan,
      ...(processingError && { warning: processingError })
    }

    console.log('üéâ Upload completed successfully!')
    res.status(200).json(response)

  } catch (error: any) {
    console.error('‚ùå Upload error:', error.message, error.stack)
    res.status(500).json({ 
      error: 'Upload failed. Please try again with a smaller file or different format.',
      details: error.message
    })
  }
}

export default handler 